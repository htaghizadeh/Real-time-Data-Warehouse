{
  "metadata" : {
    "config" : {
      "dependencies" : {
        "scala" : [
          "io.delta:delta-core_2.12:1.0.0",
          "org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.2",
          "org.antlr:antlr4-runtime:4.8-1"
        ]
      },
      "exclusions" : [
      ],
      "repositories" : [
      ],
      "sparkConfig" : {
        "spark.sql.extensions" : "io.delta.sql.DeltaSparkSessionExtension",
        "spark.sql.catalog.spark_catalog" : "org.apache.spark.sql.delta.catalog.DeltaCatalog"
      },
      "env" : {
        
      }
    },
    "language_info" : {
      "name" : "scala"
    }
  },
  "nbformat" : 4,
  "nbformat_minor" : 0,
  "cells" : [
    {
      "cell_type" : "markdown",
      "execution_count" : 0,
      "metadata" : {
        "language" : "text"
      },
      "language" : "text",
      "source" : [
        "# <br>\n",
        "\n",
        "\n"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 1,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1625837271482,
          "endTs" : 1625837272121
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "spark.version"
      ],
      "outputs" : [
        {
          "execution_count" : 1,
          "data" : {
            "text/plain" : [
              "3.1.2"
            ]
          },
          "metadata" : {
            "name" : "Out",
            "type" : "String"
          },
          "output_type" : "execute_result"
        }
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 2,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1625837340219,
          "endTs" : 1625837346029
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "val data = spark.range(0, 5)\n",
        "data.write.format(\"delta\").save(\"/tmp/delta-table\")"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 9,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1625837395960,
          "endTs" : 1625837396083
        },
        "language" : "sql"
      },
      "language" : "sql",
      "source" : [
        "SELECT * from delta.`/tmp/delta-table`"
      ],
      "outputs" : [
        {
          "ename" : "java.lang.LinkageError",
          "evalue" : "loader constraint violation: when resolving method 'java.lang.Object org.apache.spark.sql.catalyst.parser.ParserUtils$.withOrigin(org.antlr.v4.runtime.ParserRuleContext, scala.Function0)' the class loader polynote.kernel.util.LimitedSharingClassLoader @5e835200 of the current class, io/delta/sql/parser/DeltaSqlAstBuilder, and the class loader 'app' for the method's defining class, org/apache/spark/sql/catalyst/parser/ParserUtils$, have different Class objects for the type org/antlr/v4/runtime/ParserRuleContext used in the signature (io.delta.sql.parser.DeltaSqlAstBuilder is in unnamed module of loader polynote.kernel.util.LimitedSharingClassLoader @5e835200, parent loader 'app'; org.apache.spark.sql.catalyst.parser.ParserUtils$ is in unnamed module of loader 'app')",
          "traceback" : [
            "io.delta.sql.parser.DeltaSqlAstBuilder,visitSingleStatement,DeltaSqlParser.scala,187",
            "io.delta.sql.parser.DeltaSqlAstBuilder,visitSingleStatement,DeltaSqlParser.scala,142",
            "io.delta.sql.parser.DeltaSqlBaseParser$SingleStatementContext,accept,DeltaSqlBaseParser.java,149",
            "org.antlr.v4.runtime.tree.AbstractParseTreeVisitor,visit,AbstractParseTreeVisitor.java,18",
            "io.delta.sql.parser.DeltaSqlParser,$anonfun$parsePlan$1,DeltaSqlParser.scala,70",
            "io.delta.sql.parser.DeltaSqlParser,parse,DeltaSqlParser.scala,99",
            "io.delta.sql.parser.DeltaSqlParser,parsePlan,DeltaSqlParser.scala,69",
            "org.apache.spark.sql.SparkSession,$anonfun$sql$2,SparkSession.scala,616",
            "org.apache.spark.sql.catalyst.QueryPlanningTracker,measurePhase,QueryPlanningTracker.scala,111",
            "org.apache.spark.sql.SparkSession,$anonfun$sql$1,SparkSession.scala,616",
            "org.apache.spark.sql.SparkSession,withActive,SparkSession.scala,775",
            "org.apache.spark.sql.SparkSession,sql,SparkSession.scala,613",
            "polynote.kernel.interpreter.sql.SparkSqlInterpreter,$anonfun$run$8,SparkSqlInterpreter.scala,43",
            "zio.internal.FiberContext,evaluateNow,FiberContext.scala,490",
            "zio.internal.FiberContext,$anonfun$evaluateLater$1,FiberContext.scala,775",
            "polynote.kernel.interpreter.CellExecutor$$anon$1,$anonfun$run$2,CellExecutor.scala,33",
            "scala.runtime.java8.JFunction0$mcV$sp,apply,JFunction0$mcV$sp.java,23",
            "scala.util.DynamicVariable,withValue,DynamicVariable.scala,62",
            "scala.Console$,withOut,Console.scala,167",
            "polynote.kernel.interpreter.CellExecutor$$anon$1,$anonfun$run$1,CellExecutor.scala,33",
            "scala.runtime.java8.JFunction0$mcV$sp,apply,JFunction0$mcV$sp.java,23",
            "polynote.kernel.package$,withContextClassLoader,package.scala,95",
            "polynote.kernel.interpreter.CellExecutor$$anon$1,run,CellExecutor.scala,31",
            "java.util.concurrent.ThreadPoolExecutor,runWorker,ThreadPoolExecutor.java,1128",
            "java.util.concurrent.ThreadPoolExecutor$Worker,run,ThreadPoolExecutor.java,628",
            "java.lang.Thread,run,Thread.java,829"
          ],
          "output_type" : "error"
        }
      ]
    }
  ]
}